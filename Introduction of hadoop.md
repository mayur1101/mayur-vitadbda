# Introduction to hadoop
<img src="Images/hadoop logo.png" width=200>

->It is a apache based open source framework.

->It is implemented in java.

->It has a distributed storage i.e. we can store data in multiple nodes in cluster and it is done by HDFS(hadoop distributed file system).

->It has a distributed processing and it is accomplished by mapreduce.

->In hadoop simple programming model is maintained.

->It supports parallel processing for fast processing.

->Is has local compuation and storage.

# Brief history of hadoop
History of Hadoop had started in the year 2002 with the project Apache Nutch. Hadoop was created by Doug Cutting, the creator of Apache Lucene, the widely used text search library. Hadoop has its origins in Apache Nutch, an open source web search engine which itself is a part of Lucene Project.

- Journey of hadoop starts from 2005.But before that also it is described.As teh google has published the research paper on google file system.On the basis of this paper hadoop is made.

- Hadoop is made by doug cutting in 2005 Earlier they are working in google in web crawling.They used to retrieve data and the main problem is to store data because the 
data is in terabytes.Therefore he made HDFS and MAP REDUCE.He says that HDFS is the storage engine and we can store any type of data that is structured non structured any data.
To process that data he ,ade processing framework named MAP REDUCE.

- Why name hadoop?because doug cutting child have a toy of elephant and of yellow colour and his boy used to say that toy as a hadoop hadoop thats why cutting gave thename hadoop.

- The main reason that made hadoop popular is distributed system(Backbone of hadoop) and parallel processing.

- In 2008-2010 it became very popular because of facebook has the license of oracle it is very costly.So facebook came to the solution for this as a hadoop cluster.They made hadoop cluster popular.

- Earlier also it is used by YAHOO to store their personalized content(The content which we see through adds and the news i.e. what we search we get the data as per that).

- Yahoo had made 200 node cluster.

- Map reduce is based on pure java programming.And java experts are required to made map reduce programs.

- Yahoo researched for skilled set in their company and they see the unix linux system resources are there.So what they have done they hire the java expert team and they make 
a framework called PIG.

- So pig now is used to convert the linux style commands into the map reduce.

- Facebook has also has problem because they r using oracle thats why they have expertise of sql.Then they have also hire java experts and they made HIVE system.Now they can
write sql query in hive and hive converts it into map reduce.Therefore hive is used for structured data.

- So as we see that in hadoop ecosystems all applications have the name of animals so to keep safe that is not to try something officially change the data of aother applications
There is a zookeeper that manages the privacy of applications in ecosystem.

[`Click here to see history of hadoop`](https://youtu.be/JMmlc7SNh7o)

<img src="Images/history of hadoop.png" width=600>
